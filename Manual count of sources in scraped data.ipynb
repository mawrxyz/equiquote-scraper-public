{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cad4ef0",
   "metadata": {},
   "source": [
    "# Counting sources in scraped news articles \n",
    "\n",
    "I wrote a simple program to make it easier to take a CSV with data scraped from various news outlets and EquiQuote's results for them, extract the counts of male and female sources, add the user's own counts and any comments, detect if there is a match and then add all of these numbers back to the CSV. \n",
    "\n",
    "This was just to make the process manageable and accurate, so I didn't get overwhelmed looking through and annotating 75 articles with up to 1000 words in text each. Parts of the code can also be repurposed for other content analysis work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b7b6abfa",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'Rectangle:kwdoc'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/docstring.py:61\u001b[0m, in \u001b[0;36m_ArtistKwdocLoader.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _recursive_subclasses(Artist)\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m name]\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 1)",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [78]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mre\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mast\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m literal_eval\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/pyplot.py:57\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m docstring\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m FigureCanvasBase, MouseButton\n\u001b[0;32m---> 57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfigure\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Figure, figaspect\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgridspec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSpec, SubplotSpec\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m rcParams, rcParamsDefault, get_backend, rcParamsOrig\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/figure.py:25\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _blocking_input, docstring, projections\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01martist\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     27\u001b[0m     Artist, allow_rasterization, _finalize_rasterization)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend_bases\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     29\u001b[0m     FigureCanvasBase, NonGuiException, MouseButton, _get_renderer)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/projections/__init__.py:55\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mNon-separable transforms that map from data space to screen space.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m`matplotlib.projections.polar` may also be of interest.\u001b[39;00m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m---> 55\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m axes, docstring\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgeo\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AitoffAxes, HammerAxes, LambertAxes, MollweideAxes\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpolar\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m PolarAxes\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/__init__.py:1\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_subplots\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_axes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_subplots.py:3\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmpl\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m _api, cbook\n\u001b[0;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01maxes\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_axes\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Axes\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgridspec\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m GridSpec, SubplotSpec\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mSubplotBase\u001b[39;00m:\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py:47\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     39\u001b[0m _log \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     42\u001b[0m \u001b[38;5;66;03m# The axes module contains all the wrappers to plotting functions.\u001b[39;00m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# All the other methods should go in the _AxesBase class.\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;129m@docstring\u001b[39m\u001b[38;5;241m.\u001b[39minterpd\n\u001b[0;32m---> 47\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mAxes\u001b[39;00m(_AxesBase):\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;124;03m    The `Axes` contains most of the figure elements: `~.axis.Axis`,\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;124;03m    `~.axis.Tick`, `~.lines.Line2D`, `~.text.Text`, `~.patches.Polygon`, etc.,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     64\u001b[0m \n\u001b[1;32m     65\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m     66\u001b[0m     \u001b[38;5;66;03m### Labelling, legend and texts\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/axes/_axes.py:371\u001b[0m, in \u001b[0;36mAxes\u001b[0;34m()\u001b[0m\n\u001b[1;32m    366\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madd_child_axes(inset_ax)\n\u001b[1;32m    368\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inset_ax\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;129;43m@docstring\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdedent_interpd\u001b[49m\n\u001b[0;32m--> 371\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mdef\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;21;43mindicate_inset\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbounds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minset_ax\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    372\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m0.5\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    373\u001b[0m \u001b[43m                   \u001b[49m\u001b[43mzorder\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m4.99\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m    374\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43;03m\"\"\"\u001b[39;49;00m\n\u001b[1;32m    375\u001b[0m \u001b[38;5;124;43;03m    Add an inset indicator to the Axes.  This is a rectangle on the plot\u001b[39;49;00m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;124;43;03m    at the position indicated by *bounds* that optionally has lines that\u001b[39;49;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    427\u001b[0m \n\u001b[1;32m    428\u001b[0m \u001b[38;5;124;43;03m    \"\"\"\u001b[39;49;00m\n\u001b[1;32m    429\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# to make the axes connectors work, we need to apply the aspect to\u001b[39;49;00m\n\u001b[1;32m    430\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# the parent axes.\u001b[39;49;00m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/docstring.py:84\u001b[0m, in \u001b[0;36m_ArtistPropertiesSubstitution.__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, obj):\n\u001b[0;32m---> 84\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mobj\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj, \u001b[38;5;28mtype\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mobject\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m:\n\u001b[1;32m     86\u001b[0m         \u001b[38;5;28mself\u001b[39m(obj\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m)\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/docstring.py:38\u001b[0m, in \u001b[0;36mSubstitution.__call__\u001b[0;34m(self, func)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, func):\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m:\n\u001b[0;32m---> 38\u001b[0m         func\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__doc__\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcleandoc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__doc__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m%\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/matplotlib/docstring.py:64\u001b[0m, in \u001b[0;36m_ArtistKwdocLoader.__missing__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[38;5;28mcls\u001b[39m, \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mcls\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mcls\u001b[39m \u001b[38;5;129;01min\u001b[39;00m _recursive_subclasses(Artist)\n\u001b[1;32m     62\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m name]\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msetdefault(key, kwdoc(\u001b[38;5;28mcls\u001b[39m))\n",
      "\u001b[0;31mKeyError\u001b[0m: 'Rectangle:kwdoc'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "from ast import literal_eval\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336f55cb",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2c03c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_counts(sources_detected):\n",
    "    '''Extract the number of sources from each gender and add them as separate columns'''\n",
    "    \n",
    "    men_count = 0\n",
    "    women_count = 0\n",
    "    \n",
    "    # Handle cases where sources aren't detected or output is in the wrong format\n",
    "    if not sources_detected or isinstance(sources_detected, (float, int)):\n",
    "        return men_count, women_count\n",
    "    \n",
    "    # If sources_detected is a string, convert it to a list\n",
    "    if isinstance(sources_detected, str):\n",
    "        sources_detected = literal_eval(sources_detected)\n",
    "\n",
    "    for source in sources_detected:\n",
    "        if 'Male' in source['Gender']:\n",
    "            men_count += 1\n",
    "        elif 'Female' in source['Gender']:\n",
    "            women_count += 1\n",
    "\n",
    "    return men_count, women_count\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "58657ad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk_text(text, chunk_size=200):\n",
    "    '''Display text in smaller chunks so it's easier to read'''\n",
    "    \n",
    "    if not isinstance(text, str):\n",
    "        print(\"Text not detected. Skipping...\")\n",
    "        return 0, 0\n",
    "\n",
    "    words = text.split()\n",
    "    total_men, total_women = 0, 0\n",
    "    \n",
    "    for i in range(0, len(words), chunk_size):\n",
    "        while True:  # Loop in case of need to redo\n",
    "            \n",
    "            print(\" \".join(words[i:i+chunk_size]))  # Print up to 200 words (or whatever chunk size specified)\n",
    "            \n",
    "            action = ''\n",
    "            # Check for \"restart\" at any point\n",
    "            if action == 'restart':\n",
    "                return 'restart', 'restart'\n",
    "            \n",
    "            print(\"\\n\" + \"-\"*40 + \"\\n\")\n",
    "            \n",
    "            while True:  # Loop to handle 'Number of new men quoted' input\n",
    "                try:\n",
    "                    chunk_men = int(input(\"Number of new men quoted: \"))\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    print(\"Invalid input. Please enter a number.\")\n",
    "\n",
    "            while True:  # Loop to handle 'Number of new women quoted' input\n",
    "                try:\n",
    "                    chunk_women = int(input(\"Number of new women quoted: \"))\n",
    "                    break\n",
    "                except ValueError:\n",
    "                    print(\"Invalid input. Please enter a number.\")\n",
    "\n",
    "            action = input(f\"You entered {chunk_men} men and {chunk_women} women for this chunk. Press Enter to continue or type 'redo' to re-evaluate: \").lower()\n",
    "            \n",
    "            print(\"\\n\" + \"-\"*40 + \"\\n\")\n",
    "            \n",
    "            if action != 'redo':\n",
    "                total_men += chunk_men\n",
    "                total_women += chunk_women\n",
    "                break\n",
    "        \n",
    "    return total_men, total_women"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "453da166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sources(sources_list):\n",
    "    '''Format the sources EquiQuote has detected (which is a string with a list of dictionaries)\\\n",
    "    such that it just lists the men and women detected'''\n",
    "    \n",
    "    if isinstance(sources_list, str):\n",
    "        sources_list = literal_eval(sources_list)\n",
    "\n",
    "    men_quoted, women_quoted = [], []\n",
    "\n",
    "    for source in sources_list:\n",
    "        if 'Male' in source['Gender']:\n",
    "            men_quoted.append(source['Source'])\n",
    "        elif 'Female' in source['Gender']:\n",
    "            women_quoted.append(source['Source'])\n",
    "\n",
    "    print(\"Men quoted:\")\n",
    "    for man in men_quoted:\n",
    "        print(man)\n",
    "\n",
    "    print(\"\\nWomen quoted:\")\n",
    "    for woman in women_quoted:\n",
    "        print(woman)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "55ba1dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def manual_evaluation(df):\n",
    "    '''Prompts to print the link and text of each story and then enter my counts for men, women, and any comments.\n",
    "    Automatically check for matches with EquiQuote counts'''\n",
    "        \n",
    "    # List out the story links\n",
    "    print(\"\\nAvailable story links in this CSV file:\\n\" + \"-\"*60)\n",
    "    for i, link in enumerate(df['link']):\n",
    "        print(f\"{i + 1}. {link}\")\n",
    "    print(\"-\"*60)\n",
    "\n",
    "    # Option to start from a certain story\n",
    "    start_input = input(\"Enter the number of the story you want to start processing from (or press Enter to start from the first story): \")\n",
    "    start_from_story = int(start_input) - 1 if start_input else 0\n",
    "    \n",
    "    for index, row in df.iloc[start_from_story:].iterrows():\n",
    "        \n",
    "        while True: # Loop this in case I want to redo after checking \n",
    "\n",
    "            print(f\"Story link: {row['link']}\\n\" + \"-\"*40 + \"\\n\")\n",
    "\n",
    "                    \n",
    "            total_men, total_women = chunk_text(row[\"text\"])\n",
    "            \n",
    "            if total_men == 'restart' and total_women == 'restart':\n",
    "                return manual_evaluation(df)\n",
    "\n",
    "            # Check if the return value indicates a delete\n",
    "            elif total_men == 'delete' and total_women == 'delete':\n",
    "                df.drop(index, inplace=True)\n",
    "                \n",
    "                # Confirm saving the CSV immediately after dropping the row\n",
    "                save_input = input(f\"Do you want to save changes to {csv_file}? (yes/no): \")\n",
    "                if save_input.lower() == 'yes':\n",
    "                    df.to_csv(file_path, index=False)\n",
    "                return manual_evaluation(df)\n",
    "            \n",
    "            df.at[index, \"my_count_men\"] = total_men\n",
    "            df.at[index, \"my_count_women\"] = total_women\n",
    "\n",
    "            # Check for match automatically\n",
    "            df.at[index, \"match\"] = (total_men == df.at[index, \"count_men\"]) and (total_women == df.at[index, \"count_women\"])\n",
    "\n",
    "            # Print out results to check\n",
    "            print(f\"EquiQuote counted {df.at[index, 'count_women']} women and {df.at[index, 'count_men']} men. You counted {total_women} women and {total_men} men. Was this a match? {'Yes' if df.at[index, 'match'] else 'No'}.\")\n",
    "\n",
    "            while True:  # Loop to handle 'See sources' input\n",
    "                see_sources = input(\"See sources detected by EquiQuote? (yes/no): \").lower()\n",
    "                if see_sources in ['yes', 'no']:\n",
    "                    break\n",
    "                print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
    "\n",
    "            if see_sources == 'yes':\n",
    "                format_sources(df.at[index, \"sources_detected\"])\n",
    "            \n",
    "            my_count_comments = input(\"Add comments if any (else 'NA'): \")\n",
    "            if not my_count_comments.strip():\n",
    "                my_count_comments = \"NA\"\n",
    "            df.at[index, \"my_count_comments\"] = my_count_comments\n",
    "\n",
    "            while True:  # Loop to handle 'redo' input\n",
    "                redo = input(\"Do you want to redo? (yes/no): \").lower()\n",
    "                if redo in ['yes', 'no']:\n",
    "                    break\n",
    "                print(\"Invalid input. Please enter 'yes' or 'no'.\")\n",
    "\n",
    "            if redo != 'yes':\n",
    "                break\n",
    "        \n",
    "        # Confirm saving the CSV\n",
    "        save_input = input(f\"Do you want to save changes to {csv_file}? (yes/no): \")\n",
    "        if save_input.lower() == 'yes':\n",
    "            df.to_csv(file_path, index=False)\n",
    "    \n",
    "        # Option to restart or continue\n",
    "        restart_input = input(\"Press Enter to continue to the next story, or type 'restart' to go back to the beginning: \")\n",
    "        print(\"\\n\" + \"-\"*40 + \"\\n\")\n",
    "        \n",
    "        if restart_input.lower() == 'restart':\n",
    "            return manual_evaluation(df)\n",
    "            \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4007e3ed",
   "metadata": {},
   "source": [
    "## Run the code "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "fc35634a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open CSV files in alphabetical order\n",
    "\n",
    "data_dir = \"data\"\n",
    "csv_files = sorted([f for f in os.listdir(data_dir) if f.endswith('.csv')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "a90d6994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CSV files:\n",
      "------------------------------------------------------------\n",
      "1. BBC_2023-08-17.csv\n",
      "2. BBC_2023-08-18.csv\n",
      "3. BBC_2023-08-19.csv\n",
      "4. BBC_2023-08-20.csv\n",
      "5. BBC_2023-08-21.csv\n",
      "6. Mail_2023-08-17.csv\n",
      "7. Mail_2023-08-18.csv\n",
      "8. Mail_2023-08-19.csv\n",
      "9. Mail_2023-08-20.csv\n",
      "10. Mail_2023-08-21.csv\n",
      "11. Sun_2023-08-17.csv\n",
      "12. Sun_2023-08-18.csv\n",
      "13. Sun_2023-08-19.csv\n",
      "14. Sun_2023-08-20.csv\n",
      "15. Sun_2023-08-21.csv\n",
      "------------------------------------------------------------\n",
      "Enter the number of the file you want to start processing from (or press Enter to start from the first file): 1\n",
      "------------------------------------------------------------\n",
      "Processing: BBC_2023-08-17.csv\n",
      "------------------------------------------------------------\n",
      "\n",
      "Available story links in this CSV file:\n",
      "------------------------------------------------------------\n",
      "1. https://www.bbc.co.uk/news/entertainment-arts-66533004\n",
      "2. https://www.bbc.co.uk/news/education-66473620\n",
      "3. https://www.bbc.co.uk/news/world-africa-66537871\n",
      "4. https://www.bbc.co.uk/news/world-europe-66538638\n",
      "5. https://www.bbc.co.uk/news/world-us-canada-66529567\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [124]\u001b[0m, in \u001b[0;36m<cell line: 11>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     31\u001b[0m                 df[column] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;66;03m# Run manual evaluation\u001b[39;00m\n\u001b[0;32m---> 34\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mmanual_evaluation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEvaluation completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Input \u001b[0;32mIn [58]\u001b[0m, in \u001b[0;36mmanual_evaluation\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m60\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Option to start from a certain story\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m start_input \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter the number of the story you want to start processing from (or press Enter to start from the first story): \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m start_from_story \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(start_input) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m start_input \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m index, row \u001b[38;5;129;01min\u001b[39;00m df\u001b[38;5;241m.\u001b[39miloc[start_from_story:]\u001b[38;5;241m.\u001b[39miterrows():\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1074\u001b[0m     )\n\u001b[0;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/anaconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "# Print out the list of CSV files\n",
    "print(\"Available CSV files:\\n\" + \"-\"*60)\n",
    "for i, csv in enumerate(csv_files):\n",
    "    print(f\"{i + 1}. {csv}\")\n",
    "print(\"-\"*60)\n",
    "\n",
    "# Option to start from particular file\n",
    "start_input = input(\"Enter the number of the file you want to start processing from (or press Enter to start from the first file): \")\n",
    "start_from = int(start_input) - 1 if start_input else 0\n",
    "\n",
    "for csv_file in csv_files[start_from:]:\n",
    "    \n",
    "    print(\"-\"*60)\n",
    "    print(f\"Processing: {csv_file}\\n\" + \"-\"*60)\n",
    "    \n",
    "    # Load the CSV file\n",
    "    file_path = os.path.join(data_dir, csv_file)\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Extract counts from sources detected\n",
    "    df[\"count_men\"], df[\"count_women\"] = zip(*df[\"sources_detected\"].apply(extract_counts))\n",
    "    \n",
    "    # Initialise new columns with default values\n",
    "    df[\"my_count_comments\"] = \"NA\"\n",
    "    \n",
    "    for column in [\"my_count_men\", \"my_count_women\", \"match\"]:\n",
    "        if column not in df.columns:\n",
    "            if column.startswith(\"my_count\"):\n",
    "                df[column] = 0\n",
    "            else:\n",
    "                df[column] = False\n",
    "    \n",
    "    # Run manual evaluation\n",
    "    df = manual_evaluation(df)\n",
    "   \n",
    "print(\"Evaluation completed!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfcbdfe7",
   "metadata": {},
   "source": [
    "## Analyse results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a6319b71",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tally_accuracy(csv_files, data_dir):\n",
    "    '''After manually evaluating the CSV files, count the number of matches and tally the accuracy/match rate'''\n",
    "    \n",
    "    sources = [\"BBC\", \"Mail\", \"Sun\"]\n",
    "    data = {source: {\"matches\": 0, \"non_matches\": 0} for source in sources}\n",
    "\n",
    "    for file in csv_files:\n",
    "        df = pd.read_csv(os.path.join(data_dir, file))\n",
    "        for source in sources:\n",
    "            if file.startswith(source):\n",
    "                data[source][\"matches\"] += df[\"match\"].sum()\n",
    "                data[source][\"non_matches\"] += len(df) - df[\"match\"].sum()\n",
    "\n",
    "    total_matches = sum([data[source][\"matches\"] for source in sources])\n",
    "    total_non_matches = sum([data[source][\"non_matches\"] for source in sources])\n",
    "    \n",
    "    results = []\n",
    "    \n",
    "    for source in sources:\n",
    "        matches = data[source][\"matches\"]\n",
    "        non_matches = data[source][\"non_matches\"]\n",
    "        total = matches + non_matches\n",
    "        accuracy = round((matches / total) * 100, 2) if total != 0 else 0\n",
    "        results.append([source, matches, non_matches, accuracy])  # This line is important\n",
    "    \n",
    "    total_accuracy = (total_matches / (total_matches + total_non_matches)) * 100 if (total_matches + total_non_matches) != 0 else 0\n",
    "    results.append([\"Total\", total_matches, total_non_matches, round(total_accuracy, 2)])\n",
    "\n",
    "    df_results = pd.DataFrame(results, columns=[\"Source\", \"Matches\", \"Non-matches\", \"Accuracy (%)\"])\n",
    "    \n",
    "    # Display the table\n",
    "    print(df_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "cfde025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Source  Matches  Non-matches  Accuracy (%)\n",
      "0    BBC       20            3         86.96\n",
      "1   Mail       15            8         65.22\n",
      "2    Sun       22            3         88.00\n",
      "3  Total       57           14         80.28\n"
     ]
    }
   ],
   "source": [
    "# Overall tally\n",
    "tally_accuracy(csv_files, data_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "f3094fad",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/sp/2pgyrj793q75rz3r54qwl25c0000gp/T/ipykernel_50018/53164937.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mismatches['file_name'] = csv_file\n",
      "/var/folders/sp/2pgyrj793q75rz3r54qwl25c0000gp/T/ipykernel_50018/53164937.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mismatches['file_name'] = csv_file\n",
      "/var/folders/sp/2pgyrj793q75rz3r54qwl25c0000gp/T/ipykernel_50018/53164937.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mismatches['file_name'] = csv_file\n",
      "/var/folders/sp/2pgyrj793q75rz3r54qwl25c0000gp/T/ipykernel_50018/53164937.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mismatches['file_name'] = csv_file\n",
      "/var/folders/sp/2pgyrj793q75rz3r54qwl25c0000gp/T/ipykernel_50018/53164937.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mismatches['file_name'] = csv_file\n",
      "/var/folders/sp/2pgyrj793q75rz3r54qwl25c0000gp/T/ipykernel_50018/53164937.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mismatches['file_name'] = csv_file\n",
      "/var/folders/sp/2pgyrj793q75rz3r54qwl25c0000gp/T/ipykernel_50018/53164937.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mismatches['file_name'] = csv_file\n",
      "/var/folders/sp/2pgyrj793q75rz3r54qwl25c0000gp/T/ipykernel_50018/53164937.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mismatches['file_name'] = csv_file\n",
      "/var/folders/sp/2pgyrj793q75rz3r54qwl25c0000gp/T/ipykernel_50018/53164937.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  mismatches['file_name'] = csv_file\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>count_men</th>\n",
       "      <th>my_count_men</th>\n",
       "      <th>count_women</th>\n",
       "      <th>my_count_women</th>\n",
       "      <th>my_count_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC_2023-08-18.csv</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-66120934</td>\n",
       "      <td>Hospital bosses failed to investigate allegati...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EquiQuote identified Dr Ravi as a source, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBC_2023-08-19.csv</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-merseysi...</td>\n",
       "      <td>The former chair of the NHS trust where serial...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>In this case, EquiQuote identified Sir Duncan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBC_2023-08-21.csv</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-merseysi...</td>\n",
       "      <td>Neonatal nurse Lucy Letby, who is the UK's mos...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>It missed a short quote from Rishi Sunak sayin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mail_2023-08-17.csv</td>\n",
       "      <td>https://www.dailymail.co.uk/tvshowbiz/article-...</td>\n",
       "      <td>Britney Spears' estranged husband Sam Asghari ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>It detected Sam Asghari as a source, but I thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mail_2023-08-17.csv</td>\n",
       "      <td>https://www.dailymail.co.uk/news/article-12418...</td>\n",
       "      <td>A mother-of-three has been spared jail for a f...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>It missed an unnamed female police officer.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_name                                               link   \n",
       "0   BBC_2023-08-18.csv             https://www.bbc.co.uk/news/uk-66120934  \\\n",
       "1   BBC_2023-08-19.csv  https://www.bbc.co.uk/news/uk-england-merseysi...   \n",
       "2   BBC_2023-08-21.csv  https://www.bbc.co.uk/news/uk-england-merseysi...   \n",
       "3  Mail_2023-08-17.csv  https://www.dailymail.co.uk/tvshowbiz/article-...   \n",
       "4  Mail_2023-08-17.csv  https://www.dailymail.co.uk/news/article-12418...   \n",
       "\n",
       "                                                text  count_men  my_count_men   \n",
       "0  Hospital bosses failed to investigate allegati...          2             1  \\\n",
       "1  The former chair of the NHS trust where serial...          3             2   \n",
       "2  Neonatal nurse Lucy Letby, who is the UK's mos...          4             5   \n",
       "3  Britney Spears' estranged husband Sam Asghari ...          2             1   \n",
       "4  A mother-of-three has been spared jail for a f...          2             2   \n",
       "\n",
       "   count_women  my_count_women   \n",
       "0            0               0  \\\n",
       "1            2               1   \n",
       "2            4               4   \n",
       "3            0               0   \n",
       "4            1               2   \n",
       "\n",
       "                                   my_count_comments  \n",
       "0  EquiQuote identified Dr Ravi as a source, but ...  \n",
       "1  In this case, EquiQuote identified Sir Duncan ...  \n",
       "2  It missed a short quote from Rishi Sunak sayin...  \n",
       "3  It detected Sam Asghari as a source, but I thi...  \n",
       "4        It missed an unnamed female police officer.  "
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Table of rows where there was a disagreement between my and EquiQuote's judgment\n",
    "\n",
    "no_match = [] \n",
    "\n",
    "columns = ['file_name', 'link', 'text', 'count_men', 'my_count_men', 'count_women', 'my_count_women', 'my_count_comments']\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(data_dir, csv_file)\n",
    "    \n",
    "    # Read the CSV into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if \"match\" column exists\n",
    "    if \"match\" in df.columns:\n",
    "        # Filter out rows where \"match\" is FALSE\n",
    "        mismatches = df[df[\"match\"] == False]\n",
    "        \n",
    "        # Add a column to the mismatches DataFrame for the CSV file name\n",
    "        mismatches['file_name'] = csv_file\n",
    "        \n",
    "        # Append mismatches to the no_match list\n",
    "        no_match.append(mismatches[columns])\n",
    "\n",
    "# Concatenate all mismatched DataFrames\n",
    "mismatch_df = pd.concat(no_match, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "fa55e067",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file_name</th>\n",
       "      <th>link</th>\n",
       "      <th>text</th>\n",
       "      <th>count_men</th>\n",
       "      <th>my_count_men</th>\n",
       "      <th>count_women</th>\n",
       "      <th>my_count_women</th>\n",
       "      <th>my_count_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BBC_2023-08-18.csv</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-66120934</td>\n",
       "      <td>Hospital bosses failed to investigate allegati...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>EquiQuote identified Dr Ravi as a source, but ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BBC_2023-08-19.csv</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-merseysi...</td>\n",
       "      <td>The former chair of the NHS trust where serial...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>In this case, EquiQuote identified Sir Duncan ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BBC_2023-08-21.csv</td>\n",
       "      <td>https://www.bbc.co.uk/news/uk-england-merseysi...</td>\n",
       "      <td>Neonatal nurse Lucy Letby, who is the UK's mos...</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>It missed a short quote from Rishi Sunak sayin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mail_2023-08-17.csv</td>\n",
       "      <td>https://www.dailymail.co.uk/tvshowbiz/article-...</td>\n",
       "      <td>Britney Spears' estranged husband Sam Asghari ...</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>It detected Sam Asghari as a source, but I thi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mail_2023-08-17.csv</td>\n",
       "      <td>https://www.dailymail.co.uk/news/article-12418...</td>\n",
       "      <td>A mother-of-three has been spared jail for a f...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>It missed an unnamed female police officer.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file_name                                               link   \n",
       "0   BBC_2023-08-18.csv             https://www.bbc.co.uk/news/uk-66120934  \\\n",
       "1   BBC_2023-08-19.csv  https://www.bbc.co.uk/news/uk-england-merseysi...   \n",
       "2   BBC_2023-08-21.csv  https://www.bbc.co.uk/news/uk-england-merseysi...   \n",
       "3  Mail_2023-08-17.csv  https://www.dailymail.co.uk/tvshowbiz/article-...   \n",
       "4  Mail_2023-08-17.csv  https://www.dailymail.co.uk/news/article-12418...   \n",
       "\n",
       "                                                text  count_men  my_count_men   \n",
       "0  Hospital bosses failed to investigate allegati...          2             1  \\\n",
       "1  The former chair of the NHS trust where serial...          3             2   \n",
       "2  Neonatal nurse Lucy Letby, who is the UK's mos...          4             5   \n",
       "3  Britney Spears' estranged husband Sam Asghari ...          2             1   \n",
       "4  A mother-of-three has been spared jail for a f...          2             2   \n",
       "\n",
       "   count_women  my_count_women   \n",
       "0            0               0  \\\n",
       "1            2               1   \n",
       "2            4               4   \n",
       "3            0               0   \n",
       "4            1               2   \n",
       "\n",
       "                                   my_count_comments  \n",
       "0  EquiQuote identified Dr Ravi as a source, but ...  \n",
       "1  In this case, EquiQuote identified Sir Duncan ...  \n",
       "2  It missed a short quote from Rishi Sunak sayin...  \n",
       "3  It detected Sam Asghari as a source, but I thi...  \n",
       "4        It missed an unnamed female police officer.  "
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mismatch_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "9c6414fa",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. https://www.bbc.co.uk/news/uk-66120934\n",
      "EquiQuote identified Dr Ravi as a source, but he was just mentioned in a recollection of events. Brearey is the only real source.\n",
      "\n",
      "2. https://www.bbc.co.uk/news/uk-england-merseyside-66553970\n",
      "In this case, EquiQuote identified Sir Duncan Nichol as a source when actually I think he's the main newsmaker? It also identified Dr Jane Hawdon as a source, when she was quoted only through other sources. This is admittedly a challenging story, and shows where EquiQuote might struggle. \n",
      "\n",
      "3. https://www.bbc.co.uk/news/uk-england-merseyside-66569311\n",
      "It missed a short quote from Rishi Sunak saying it was \"cowardly\" for criminals not to face victims\n",
      "\n",
      "4. https://www.dailymail.co.uk/tvshowbiz/article-12418807/Britney-Spears-estranged-husband-Sam-Asghari-BREAKS-SILENCE-amid-divorce-news-says-s-t-happens-says-hold-love-respect-despite-black-eye-cheating-claims.html\n",
      "It detected Sam Asghari as a source, but I think he is the main subject here\n",
      "\n",
      "5. https://www.dailymail.co.uk/news/article-12418033/Mother-three-spared-jail-FOURTH-time-attacking-police.html\n",
      "It missed an unnamed female police officer.\n",
      "\n",
      "6. https://www.dailymail.co.uk/news/article-12421295/TV-doctor-says-ordered-apologise-Lucy-Letby-warning-hospital-bosses-government-launches-independent-probe-case-handled.html\n",
      "EquiQuote counted Dr Ravi; I didn't as I thought he was the newsmaker\n",
      "\n",
      "7. https://www.dailymail.co.uk/news/article-12394225/Lucy-Letby-left-attack-thirteen-infants.html\n",
      "EquiQuote identified Lucy Letby as a source, although she was one of the main subjects of the story. It also counted the grandmother, but I felt the she was only quoted in someone else's story. Overall, this story is a bit ambiguous\n",
      "\n",
      "8. https://www.dailymail.co.uk/news/article-12421417/Disturbing-text-messages-Lucy-Letby-murdering-innocent-babies.html\n",
      "This is really difficult! Melanie Taylor, the source detected, was actually quoted in the context of text messages to the main subject. \n",
      "\n",
      "9. https://www.dailymail.co.uk/news/article-12287421/Lucy-Letby-Bosses-Countess-Chester-Hospital-neonatal-nurse-free-murder.html\n",
      "EquiQuote left out Dr Ravi, and included Karen Rees even though she was quoted indirectly - i.e. she is \"said to have said\" something\n",
      "\n",
      "10. https://www.dailymail.co.uk/news/article-12430013/Theyve-opportunity-say-mistakes-Lucy-Letby-theyre-trying-justify-ignored-warnings-TV-doctor-Ravi-Jayaram-blasts-hospital-bosses-failed-stop-child-killer-murdering-babies-care.html\n",
      "EquiQuote recognised Dr Ravi but I think he's the newsmaker here? It's a bit subjective whether Dr Ravi is the main subject or Lucy Letby. \n",
      "\n",
      "11. https://www.dailymail.co.uk/news/article-12430291/Two-suspects-hunted-Spanish-police-gang-rape-Brit-tourist-Magaluf-arrested-France.html\n",
      "EquiQuote missed two mentions of spokesmen (for the police force and for the hotel) here\n",
      "\n",
      "12. https://www.thesun.co.uk/tv/23558499/phil-spencer-parents-killed-car-crash-vehicle-river/\n",
      "EquiQuote missed an unnamed police spokeswoman\n",
      "\n",
      "13. https://www.thesun.co.uk/news/23566815/lucy-letby-forced-hear-victims-families-sentencing-justice-sec/\n",
      "EquiQuote identified Sir Robert Buckland but I think he's the newsmaker. But it's subjective\n",
      "\n",
      "14. https://www.thesun.co.uk/fabulous/23591466/agony-queen-camilla-first-love-dies/\n",
      "EquiQuote identified Kevin Burke as an additional source. I think he's the main subject of this story (although Queen Camilla is more famous so maybe that's subjective)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Show my comments for the cases where I did not agree with EquiQuote\n",
    "\n",
    "counter = 1\n",
    "\n",
    "for csv_file in csv_files:\n",
    "    file_path = os.path.join(data_dir, csv_file)\n",
    "    \n",
    "    # Read the CSV into a DataFrame\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    # Check if \"match\" column exists\n",
    "    if \"match\" in df.columns:\n",
    "        # Filter out rows where \"match\" is FALSE\n",
    "        mismatches = df[df[\"match\"] == False]\n",
    "        \n",
    "        # Print the link above the relevant comment\n",
    "        for link, comment in zip(mismatches['link'], mismatches['my_count_comments']):\n",
    "            print(f\"{counter}. {link}\\n{comment}\\n\")\n",
    "            counter += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdd20702",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
